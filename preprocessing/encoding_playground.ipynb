{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "import random \n",
    "\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#import more_itertools as mit\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_amazon_books import tokenize_text_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "CPU times: user 2 s, sys: 526 ms, total: 2.53 s\n",
      "Wall time: 9.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not bert_loaded:\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_tokenizer.add_special_tokens({\"unk_token\": '[UNK]', 'cls_token': '[CLS]', \n",
    "                                       'pad_token':'[PAD]', 'sep_token':'[SEP]'})\n",
    "    print(len(bert_tokenizer))\n",
    "    assert bert_tokenizer.cls_token == '[CLS]'\n",
    "    bert_tokenizer.sep_token_id\n",
    "    \n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True,\n",
    "                                            output_attentions=True)\n",
    "    bert_model.resize_token_embeddings(len(bert_tokenizer))\n",
    "    \n",
    "    bert_loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta_Computers.json.gz',\n",
       " 'Electronics_5.json.gz',\n",
       " 'out-pickle',\n",
       " 'Books_5.json.gz',\n",
       " 'one_week.tar.gz',\n",
       " 'contentdata.tar.gz',\n",
       " 'books-pickle']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df.json',\n",
       " 'item_stats.pkl',\n",
       " 'pytorch_model.bin',\n",
       " 'df.csv',\n",
       " 'user_stats.pkl',\n",
       " 'df.pkl',\n",
       " 'config.json',\n",
       " 'encoded_text.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dirpath, dirnames, filenames) = next(os.walk('../datasets/books-pickle/'), (None, None, []))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_path = '../datasets/Books_5.json.gz'\n",
    "pkl_path = '../datasets/books-pickle/'\n",
    "\n",
    "with open(pkl_path + \"df.pkl\", 'rb') as fin:\n",
    "    df = pickle.load(fin)\n",
    "\n",
    "with open(pkl_path + \"user_stats.pkl\", 'rb') as fin:\n",
    "    user_dict = pickle.load(fin)\n",
    "    \n",
    "with open(pkl_path + \"item_stats.pkl\", 'rb') as fin:\n",
    "    item_dict = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-03-30</td>\n",
       "      <td>A1REUF3A1YCPHM</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>A story children will love and learn from The ...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>AVP0HXC9FG790</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars The kids loved it!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>A324TTUBKTN73A</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars My students (3 &amp; 4 year olds) loved...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>A2RE7WG349NV5D</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars LOVE IT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>A32B7QIUDQCD0E</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars Great!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified reviewTime      reviewerID      itemID  \\\n",
       "0        5     False 2005-03-30  A1REUF3A1YCPHM  0001713353   \n",
       "1        5      True 2016-06-20   AVP0HXC9FG790  0001713353   \n",
       "2        5      True 2016-01-24  A324TTUBKTN73A  0001713353   \n",
       "3        5     False 2015-07-09  A2RE7WG349NV5D  0001713353   \n",
       "4        5      True 2015-01-18  A32B7QIUDQCD0E  0001713353   \n",
       "\n",
       "                                          reviewText  reviewWords  \n",
       "0  A story children will love and learn from The ...          170  \n",
       "1                      Five Stars The kids loved it!            6  \n",
       "2  Five Stars My students (3 & 4 year olds) loved...           15  \n",
       "3                                 Five Stars LOVE IT            4  \n",
       "4                                  Five Stars Great!            3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame.from_dict(user_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>m_rating</th>\n",
       "      <th>m_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0334855HN6E38CXWXZR</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0790722OCX87RKL2J3T</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100JBBLCC0NUC</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A101OKMJFCIWYH</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1022R52JDJVMA</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      n_reviews  m_rating  m_words\n",
       "A0334855HN6E38CXWXZR          1       5.0     12.0\n",
       "A0790722OCX87RKL2J3T          1       5.0     71.0\n",
       "A100JBBLCC0NUC                1       5.0     27.0\n",
       "A101OKMJFCIWYH                2       5.0     26.0\n",
       "A1022R52JDJVMA                1       5.0     58.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.DataFrame.from_dict(item_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = bert_model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options for Encoding Sentences: \n",
    "1. Bert Embeddings (Raw): tokenise text and apply Bert Embeddings, no further processing [batch_size x seq_len x dim_e] => subsequent (sophisticated) Encoder should produce sentence representation [batch_size x dim_s]\n",
    "2. Last Hidden States: sequence encoded by Bert, powerful processing [batch_size x seq_len x dim_e] => subsequent (simple) Encoder produce sentence representation [batch_size x dim_s]\n",
    "3. Average over Last Hidden States: seq. encoded by Bert and average in the end to yield sentence representation [batch_size x dim_s]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 2.89 ms, total: 13.3 ms\n",
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_elems=2\n",
    "encoded_in = [bert_tokenizer.encode(sent, max_length=30, add_special_tokens=True, pad_to_max_length=True) for sent in list(df['reviewText'])[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = torch.tensor(encoded_in, requires_grad=False).long()\n",
    "#outputs = bert_model(x_in)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT for Sentence Encoding\n",
    "\n",
    "1. Use last hidden state of CLS \n",
    "2. Use average of last hidden states of all tokens \n",
    "3. Use average over multiple hidden layers (A) for CLS or (B) for all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef encode_sequence(df, tokenizer, sent_tokenize, bert_model, max_len=50, batch_size=2, method='cls_last', n=None):\\n\\n    encoded_text = {}\\n    start_idx = 0\\n    stop_idx = batch_size\\n\\n    while(start_idx < len(df)):\\n\\n        if stop_idx > len(df):\\n            stop_idx = len(df)\\n\\n        tokens = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text\\n                  in list(df['reviewText'])[start_idx:stop_idx]]\\n\\n        x_in = torch.tensor(tokens, requires_grad=False, device=device).long()\\n\\n        with torch.no_grad():\\n            last_hidden, pooled_out, hidden_outs, attention_weights = bert_model(x_in)\\n\\n        assert last_hidden.shape[0] == batch_size\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def encode_sequence(df, tokenizer, sent_tokenize, bert_model, max_len=50, batch_size=2, method='cls_last', n=None):\n",
    "\n",
    "    encoded_text = {}\n",
    "    start_idx = 0\n",
    "    stop_idx = batch_size\n",
    "\n",
    "    while(start_idx < len(df)):\n",
    "\n",
    "        if stop_idx > len(df):\n",
    "            stop_idx = len(df)\n",
    "\n",
    "        tokens = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text\n",
    "                  in list(df['reviewText'])[start_idx:stop_idx]]\n",
    "\n",
    "        x_in = torch.tensor(tokens, requires_grad=False, device=device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            last_hidden, pooled_out, hidden_outs, attention_weights = bert_model(x_in)\n",
    "\n",
    "        assert last_hidden.shape[0] == batch_size\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "max_len=50\n",
    "methods={'last_cls':0, 'sum_last_n':4}\n",
    "#n=4\n",
    "\n",
    "encoded_text = {}\n",
    "start_idx = 0\n",
    "stop_idx = batch_size\n",
    "\n",
    "\n",
    "##BERT for Feature-Extraction\n",
    "\n",
    "#tokenize\n",
    "tokens, _ = zip(*[tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len, lower_case=True) for text\n",
    "          in list(df['reviewText'])[start_idx:stop_idx]])\n",
    "\n",
    "x_in = torch.tensor(tokens, requires_grad=False).long() #batch_size x max_len\n",
    "\n",
    "tokens_raw, _ = zip(*[tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len, \n",
    "                                            add_special_tokens=False, lower_case=True) \n",
    "                                            for text in list(df['reviewText'])[start_idx:stop_idx]])\n",
    "\n",
    "#print(x_in.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model forward pass\n",
    "with torch.no_grad():\n",
    "    bert_outputs = bert_model(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "torch.Size([2, 50, 768])\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "last_hidden, pooled_out, hidden_outs, attention_weights = bert_outputs\n",
    "print(len(hidden_outs))\n",
    "print(hidden_outs[0].shape)\n",
    "print(len(attention_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_seq_emb(tokens, word_embeddings, method='naive_mean'):\n",
    "    tokens_emb = word_embeddings(torch.tensor(tokens))\n",
    "    if method == 'naive_mean':\n",
    "        emb_out = torch.mean(tokens_emb, dim=1)\n",
    "    elif method == 'naive_sum':\n",
    "        emb_out = torch.sum(tokens_emb, dim=1)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return emb_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 'naive_mean'\n",
    "naive_emb = get_naive_seq_emb(tokens_raw, word_embeddings, method=m)\n",
    "naive_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#save tensor of encoded text into separate dictionary\n",
    "keys = range(start_idx, stop_idx)\n",
    "\n",
    "encoded_text = defaultdict(dict)\n",
    "encodings = {}\n",
    "\n",
    "\n",
    "item_inds = range(start_idx, stop_idx) #absolute index of items of size batch_size \n",
    "slice_idx = list(range(0, len(item_inds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bert_features(bert_output, method, n_layers):\n",
    "    \"\"\"\n",
    "    \n",
    "    Argument: \n",
    "        rel_slice: index that indicates which relative slice of the output should be used\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _keys = ['pooled_out', 'last_cls', 'pool_all_last', 'pool_cls_n', 'pool_last_n', 'sum_last_n', 'sum_all']\n",
    "    \n",
    "    assert len(bert_output) == 4\n",
    "    \n",
    "    last_hidden, pooled_out, hidden_outs, attention_weights = bert_output\n",
    "    \n",
    "    if 'pooled_out' == method:\n",
    "        x_out = pooled_out # batch_size x dim_emb\n",
    "    elif 'last_cls' == method:\n",
    "        #take the embedding of CLS token of last hidden layer\n",
    "        x_out = last_hidden[:,0,:] # batch_size x dim_emb\n",
    "    elif 'pool_all_last' == method:\n",
    "        #average embeddings of last hidden layer of all tokens\n",
    "        x_out = torch.mean(last_hidden, dim=1)\n",
    "    elif 'pool_cls_n'==method:\n",
    "        # and n != None\n",
    "        x_out = torch.mean(torch.cat([hidden[:,0,:].unsqueeze(1) for hidden in hidden_outs[-n_layers:]], dim=1), dim=1)\n",
    "    elif 'pool_last_n'==method:\n",
    "        #average embeddings of last N hidden layers of all tokens\n",
    "        x_out = torch.mean(torch.cat(hidden_outs[-n_layers:], dim=1), dim=1)\n",
    "    elif 'sum_last_n' == method:\n",
    "        #sum embeddings of last N hidden layers of all tokens\n",
    "        x_out = torch.sum(torch.cat(hidden_outs[-n_layers:], dim=1), dim=1)\n",
    "        #sum last four hidden => 95.9 F1 on dev set for NER\n",
    "    elif 'sum_all'==method and n:\n",
    "        x_out = torch.sum(torch.cat(hidden_outs, dim=1), dim=1)\n",
    "    else:\n",
    "        raise KeyError(\"'{}' is not a valid method!\".format(method))\n",
    "        \n",
    "    #print(method)\n",
    "    #print(x_out.shape)\n",
    "    \n",
    "    return x_out\n",
    "\n",
    "\n",
    "def get_dummy_bert_output(batch_size, dim_bert=64, seq_len=20, n_layers=12, hidden_outs=True, attn_weights=True):\n",
    "    bert_outs = []\n",
    "    #last_hidden, pooled_out, hidden_outs, attention_weights = bert_output\n",
    "    # 1. last_hidden\n",
    "    last_hidden = torch.randn([batch_size, seq_len, dim_bert])\n",
    "    bert_outs.append(last_hidden) #batch_size x seq_len x dim_bert\n",
    "    \n",
    "    # 2. pooled_out\n",
    "    bert_outs.append(torch.randn([batch_size, dim_bert]))\n",
    "    \n",
    "    # 3. hidden_outs\n",
    "    if hidden_outs:\n",
    "        h_outs = [torch.randn([batch_size, seq_len, dim_bert]) for n in range(n_layers)]\n",
    "        h_outs.append(last_hidden)\n",
    "        bert_outs.append(h_outs)\n",
    "    \n",
    "    # 4. attn_weights\n",
    "    if attn_weights:\n",
    "        a_weights = [torch.randn([batch_size, seq_len, dim_bert]) for n in range(n_layers)]\n",
    "        bert_outs.append(a_weights)\n",
    "\n",
    "    return bert_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dummy_outs = get_dummy_bert_output(batch_size=4)\n",
    "#len(bert_dummy_outs)\n",
    "l_hidden, p_out, h_outs, a_weights = bert_dummy_outs\n",
    "#print(len(h_outs))\n",
    "#print(h_outs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# items_inds = [0, 1, 2]\n",
    "# methods = [A, B]\n",
    "# value = [tensor1, tensor2]\n",
    "\n",
    "#naive approach with slices relative to keys\n",
    "n_iterations = 0 #loops: n_methods * n_keys\n",
    "\n",
    "for (method, n) in methods.items():\n",
    "    encodings[method] = extract_bert_features(bert_outputs, method, n) #batch_size x emb_dim\n",
    "    assert encodings[method].shape[0] == len(slice_idx)\n",
    "    \n",
    "    for idx in slice_idx:\n",
    "        encoded_text[item_inds[idx]][method] = encodings[method][idx, :]\n",
    "        n_iterations+=1\n",
    "        \n",
    "print(\"Iterations: {}\" .format(n_iterations))\n",
    "#encoded_text = {**encoded_text, **dict(zip(item_inds, ))}\n",
    "    \n",
    "#encodings.items()\n",
    "#encodings['last_cls'].shape\n",
    "#encoded_text.keys()\n",
    "encoded_text[1].keys()\n",
    "#encoded_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "50\n",
      "2\n",
      "Iterations: 100\n",
      "CPU times: user 26.8 ms, sys: 0 ns, total: 26.8 ms\n",
      "Wall time: 26.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_items=50\n",
    "methods={'last_cls':0, 'sum_last_n':4}\n",
    "batch_size=6\n",
    "emb_dim = 64\n",
    "max_len=20\n",
    "\n",
    "enc_text = test_feature_extraction(n_items, methods, batch_size, emb_dim, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_text.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertFeatureExtractor():\n",
    "\n",
    "    def __init__(self, device, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.sent_tokenizer = sent_tokenize\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert_tokenizer.add_special_tokens({\"unk_token\": '[UNK]', 'cls_token': '[CLS]',\n",
    "                                           'pad_token': '[PAD]', 'sep_token': '[SEP]'})\n",
    "\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True,\n",
    "                                               output_attentions=True)\n",
    "        self.bert_model.resize_token_embeddings(len(self.bert_tokenizer))\n",
    "        self.bert_model.to(device)\n",
    "\n",
    "        self._feat_methods = ['pooled_out', 'last_cls', 'pool_all_last', 'pool_cls_n', 'pool_last_n', 'sum_last_n', 'sum_all']\n",
    "        self._naive_feat_methods = ['naive_mean', 'naive_sum']\n",
    "\n",
    "        #self.word_embeddings = \n",
    "\n",
    "\n",
    "    @property\n",
    "    def _get_feat_methods(self):\n",
    "        return self._feat_methods\n",
    "\n",
    "    @property\n",
    "    def _get_naive_feat_methods(self):\n",
    "        return self._naive_feat_methods\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.bert_model(*args, **kwargs)\n",
    "\n",
    "    def get_naive_seq_emb(self, tokens, method='naive_mean'):\n",
    "\n",
    "        if method not in self._get_naive_feat_methods():\n",
    "            raise KeyError(\"'{}' is not a valid method!\".format(method))\n",
    "        \n",
    "        word_embeddings = self.bert_model.get_input_embeddings()\n",
    "        word_embeddings.to(self.device)\n",
    "        tokens_emb = word_embeddings(torch.tensor(tokens, device=self.device)).to(self.device)\n",
    "        if method == 'naive_mean':\n",
    "            emb_out = torch.mean(tokens_emb, dim=1)\n",
    "        elif method == 'naive_sum':\n",
    "            emb_out = torch.sum(tokens_emb, dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return emb_out\n",
    "    \n",
    "    def get_bert_word_embeddings(self):\n",
    "        return self.bert_model.get_input_embeddings().to(self.device)\n",
    "\n",
    "    def extract_bert_features(self, bert_output, method, n_layers):\n",
    "        \"\"\"\n",
    "\n",
    "        Argument:\n",
    "            rel_slice: index that indicates which relative slice of the output should be used\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        assert len(bert_output) == 4\n",
    "\n",
    "        if method not in self._get_feat_methods():\n",
    "            raise KeyError(\"'{}' is not a valid method!\".format(method))\n",
    "\n",
    "        last_hidden, pooled_out, hidden_outs, attention_weights = bert_output\n",
    "\n",
    "        if 'pooled_out' == method:\n",
    "            x_out = pooled_out  # batch_size x dim_emb\n",
    "        elif 'last_cls' == method:\n",
    "            # take the embedding of CLS token of last hidden layer\n",
    "            x_out = last_hidden[:, 0, :]  # batch_size x dim_emb\n",
    "        elif 'pool_all_last' == method:\n",
    "            # average embeddings of last hidden layer of all tokens\n",
    "            x_out = torch.mean(last_hidden, dim=1)\n",
    "        elif 'pool_cls_n' == method and n_layers:\n",
    "            x_out = torch.mean(torch.cat([hidden[:, 0, :].unsqueeze(1) for hidden in hidden_outs[-n_layers:]], dim=1),\n",
    "                               dim=1)\n",
    "        elif 'pool_last_n' == method and n_layers:\n",
    "            # average embeddings of last N hidden layers of all tokens\n",
    "            x_out = torch.mean(torch.cat(hidden_outs[-n_layers:], dim=1), dim=1)\n",
    "        elif 'sum_last_n' == method and n_layers:\n",
    "            # sum embeddings of last N hidden layers of all tokens\n",
    "            x_out = torch.sum(torch.cat(hidden_outs[-n_layers:], dim=1), dim=1)\n",
    "            # sum last four hidden => 95.9 F1 on dev set for NER\n",
    "        elif 'sum_all' == method:\n",
    "            x_out = torch.sum(torch.cat(hidden_outs, dim=1), dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # print(method)\n",
    "        # print(x_out.shape)\n",
    "        return x_out\n",
    "\n",
    "    def test_feature_extraction(self, n_items, methods, batch_size, emb_dim, seq_len, **kwargs):\n",
    "\n",
    "        encoded_text = defaultdict(dict)\n",
    "        encodings = defaultdict(dict)\n",
    "        # n_items = len(df)\n",
    "\n",
    "        all_item_inds = range(n_items)\n",
    "        start_idx = 0\n",
    "        stop_idx = batch_size\n",
    "        n_iterations = 0  # loops: n_methods * n_keys\n",
    "\n",
    "        slice_idx = list(range(0, batch_size))\n",
    "\n",
    "        while (start_idx < n_items):\n",
    "\n",
    "            # handling edge cases\n",
    "            if stop_idx > n_items:\n",
    "                # indices and slice range\n",
    "                slice_idx = list(range(0, (n_items - start_idx)))\n",
    "                stop_idx = n_items\n",
    "\n",
    "            # divide item_inds into batches\n",
    "            rel_item_inds = range(start_idx, stop_idx)\n",
    "\n",
    "            # assert len(rel_item_inds) == batch_size\n",
    "            if len(rel_item_inds) != batch_size:\n",
    "                print(start_idx)\n",
    "                print(stop_idx)\n",
    "                print(len(slice_idx))\n",
    "\n",
    "            # create naive sequence features\n",
    "            naive_method = 'naive_mean'\n",
    "            # naive_emb = get_naive_seq_emb(tokens_raw, word_embeddings, method=m) #batch_size x emb_dim\n",
    "            naive_emb = torch.randn([batch_size, emb_dim])\n",
    "\n",
    "            # generate dummy BERT output\n",
    "            bert_dummy_out = get_dummy_bert_output(len(slice_idx), emb_dim, seq_len)\n",
    "\n",
    "            # extract BERT features\n",
    "            for (method, n) in methods.items():\n",
    "                encodings[method] = self.extract_bert_features(bert_dummy_out, method, n)  # batch_size x emb_dim\n",
    "\n",
    "                assert encodings[method].shape[0] == len(slice_idx)\n",
    "                # print(encodings[method].shape[0])\n",
    "                # print(len(slice_idx))\n",
    "\n",
    "                # add features to dictionary\n",
    "                for idx in slice_idx:\n",
    "                    if naive_method not in encoded_text[rel_item_inds[idx]]:\n",
    "                        encoded_text[rel_item_inds[idx]][naive_method] = naive_emb[idx, :]  # add naive features\n",
    "\n",
    "                    encoded_text[rel_item_inds[idx]][method] = encodings[method][idx, :]\n",
    "                    n_iterations += 1\n",
    "\n",
    "            start_idx += (batch_size)\n",
    "            stop_idx += (batch_size)\n",
    "\n",
    "        print(\"Iterations: {}\".format(n_iterations))\n",
    "\n",
    "        return encoded_text\n",
    "\n",
    "    def truncate_seq(self, tokens, max_len=512):\n",
    "        if len(tokens) < max_len:\n",
    "            tokens = tokens[:-1]\n",
    "            n = max_len - len(tokens) - 1\n",
    "            tokens += n * [self.bert_tokenizer.pad_token]\n",
    "        elif len(tokens) > max_len:\n",
    "            tokens = tokens[:max_len - 1]\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "        tokens.append(self.bert_tokenizer.sep_token)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def tokenize_text_to_ids(self, text, max_len=512, add_special_tokens=True, lower_case=False):\n",
    "        \"\"\"\n",
    "        With tokenizer, separate text first into tokens\n",
    "        and then convert these to corresponding IDs of the vocabulary\n",
    "\n",
    "        Return:\n",
    "            tokens: list of token IDs\n",
    "            n_words: number of words in full sequence (before truncating)\n",
    "        \"\"\"\n",
    "        sents = self.sent_tokenizer(text)\n",
    "        tokens = []\n",
    "        n_words = 0\n",
    "        added_tokens = 0\n",
    "\n",
    "        if add_special_tokens:\n",
    "            tokens.append(self.bert_tokenizer.cls_token)\n",
    "            added_tokens += 1\n",
    "\n",
    "        # split each sentence of the text into tokens\n",
    "        for s in sents:\n",
    "            if lower_case:\n",
    "                tokens.extend([word.lower() for word in self.bert_tokenizer.tokenize(s) if word.isalpha()])\n",
    "            else:\n",
    "                tokens.extend([word for word in self.bert_tokenizer.tokenize(s) if word.isalpha()])\n",
    "\n",
    "            if add_special_tokens:\n",
    "                tokens.append(self.bert_tokenizer.sep_token)\n",
    "                added_tokens += 1\n",
    "\n",
    "        n_words = len(tokens) - added_tokens\n",
    "\n",
    "        tokens = self.truncate_seq(tokens, self.bert_tokenizer, max_len)\n",
    "\n",
    "        assert len(tokens) == max_len\n",
    "\n",
    "        return self.bert_tokenizer.convert_tokens_to_ids(tokens), n_words\n",
    "\n",
    "    def encode_input_ids(self, x_in):\n",
    "        return self.bert_model(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.94 s, sys: 639 ms, total: 2.58 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_extractor = BertFeatureExtractor(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_extractor.bert_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631,\n",
       " 20631]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len=20\n",
    "\n",
    "tokens = [random.randint(1, 30522)] * seq_len\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(bert_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = torch.randint(30522, [2, seq_len]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertFeatureExtractor' object has no attribute 'encode_input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b3926388c145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertFeatureExtractor' object has no attribute 'encode_input_ids'"
     ]
    }
   ],
   "source": [
    "outputs = bert_extractor.encode_input_ids(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = ['A', 'A', 'B', 'B', 'C', 'C']\n",
    "z2 = ['k1', 'k2', 'k1', 'k2', 'k1', 'k2'] #\n",
    "z3 = ['v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "\n",
    "d = defaultdict(dict)\n",
    "for x, y, z in zip(z1, z2, z3):\n",
    "    d[x][y] = z\n",
    "\n",
    "print(dict(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = {**encoded_text, **dict(zip(keys, encodings))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 'last_cls'), (1, 'sum_last_n')])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndict1: \\n    keys:= [0 ... N] index of review\\n    value := dict2, containing encodings of that review\\n        keys: [method_1, ... , method_N]\\n        values: [enc_1, ... , enc_N]\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dict1: \n",
    "    keys:= [0 ... N] index of review\n",
    "    value := dict2, containing encodings of that review\n",
    "        keys: [method_1, ... , method_N]\n",
    "        values: [enc_1, ... , enc_N]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Encoding Text..\")\n",
    "\n",
    "bert_model.to(device)\n",
    "\n",
    "encoded_text = {}\n",
    "start_idx = 0\n",
    "stop_idx = batch_size\n",
    "\n",
    "while(start_idx < len(df)):\n",
    "\n",
    "    if stop_idx > len(df):\n",
    "        stop_idx = len(df)\n",
    "\n",
    "    encoded_in = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text\n",
    "              in list(df['reviewText'])[start_idx:stop_idx]]\n",
    "\n",
    "    encoded_in = torch.tensor(encoded_in, requires_grad=False, device=device).long()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden, pooled_out = bert_model(encoded_in)\n",
    "\n",
    "    assert last_hidden.shape[0] == batch_size\n",
    "\n",
    "    #save tensor of encoded text into separate dictionary\n",
    "    keys = range(start_idx, stop_idx+1)\n",
    "    encoded_text = {**encoded_text, **dict(zip(keys, last_hidden))}\n",
    "\n",
    "    start_idx += batch_size\n",
    "    stop_idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_representations(user_reviews, item_reviews, method='avg_items'):\n",
    "    user_repr = {}\n",
    "    for u in user_reviews.keys():\n",
    "        \n",
    "        if 'avg_items' == method:\n",
    "            stacked_reviews = torch.stack([item_reviews[i] for i in user_reviews[u].keys()])\n",
    "            #print(stacked_user_reviews.shape)\n",
    "            user_repr[u] = torch.mean(stacked_reviews, dim=0)\n",
    "        elif 'avg_items_user' == method:\n",
    "            stacked_reviews = torch.stack([item_reviews[i] for i in user_reviews[u].keys()])\n",
    "            stacked_reviews_user = torch.stack([user_reviews[u][r] for r in user_reviews[u].keys()])\n",
    "            user_repr[u] = torch.mean(stacked_reviews+stacked_reviews_user, dim=0)\n",
    "    \n",
    "    return user_repr\n",
    "\n",
    "\n",
    "def create_toy_representations(seq_emb=64, item_ids=range(100), user_ids = range(20), method='avg_items'):\n",
    "        \n",
    "    item_reviews = {}\n",
    "\n",
    "    for i in item_ids:\n",
    "        item_reviews[i] = torch.stack([torch.randn(seq_emb)] * random.randint(5,10), dim=0)\n",
    "        item_reviews[i] = torch.mean(item_reviews[i], dim=0)\n",
    "    \n",
    "    \n",
    "    user_reviews = {}\n",
    "    \n",
    "    for i in user_ids:\n",
    "        user_reviews[i] = {}\n",
    "        for r in random.sample(list(item_reviews.keys()), random.randint(5,10)):\n",
    "        #user_reviews[i] = dict(zip(random.sample(list(item_reviews.keys()), random.randint(5,10)), torch.randn(seq_emb)))\n",
    "            user_reviews[i][r] = torch.randn(seq_emb)\n",
    "            \n",
    "    return item_reviews, user_reviews, create_user_representations(user_reviews, item_reviews, method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_reviews, user_reviews, user_repr_avg = create_toy_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_repr_ui = create_user_representations(user_reviews, item_reviews, method='avg_items_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34152778796851635\n",
      "0.06405663349608343\n"
     ]
    }
   ],
   "source": [
    "cos = []\n",
    "for k in list(user_reviews[0].keys()):\n",
    "    cos.append(cosine_similarity(user_repr_avg[0].unsqueeze(0), item_reviews[k].unsqueeze(0)).item())\n",
    "    \n",
    "print(np.mean(cos))\n",
    "print(np.std(cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21049505844712257\n",
      "0.08154537465453288\n"
     ]
    }
   ],
   "source": [
    "cos = []\n",
    "for k in list(user_reviews[0].keys()):\n",
    "    cos.append(cosine_similarity(user_repr_ui[0].unsqueeze(0), item_reviews[k].unsqueeze(0)).item())\n",
    "    \n",
    "print(np.mean(cos))\n",
    "print(np.std(cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(user_repr_ui[0].unsqueeze(0), user_repr_ui[0].unsqueeze(0)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, device, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device)\n",
    "        return hidden\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, device, drop_prob=0.2, bi=False):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob, bidirectional=bi)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device))\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode user with GRU\n",
    "seq_emb = 64\n",
    "input_dim = seq_emb\n",
    "hidden_dim = seq_emb\n",
    "output_dim = seq_emb\n",
    "\n",
    "stacked_reviews = torch.stack([item_reviews[i] for i in user_reviews[0].keys()])\n",
    "n_layers = stacked_reviews.shape[0]\n",
    "batch_size = 1\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "model = GRUNet(input_dim, hidden_dim, output_dim, n_layers, device)\n",
    "h = model.init_hidden(batch_size)\n",
    "#if model_type == \"GRU\":\n",
    "h = h.data\n",
    "        \n",
    "out, h = model(stacked_reviews.unsqueeze(0).float(), h)\n",
    "print(len(h))\n",
    "user_repr_gru = h[-1].detach()\n",
    "user_repr_gru.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Sequence Encoding - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep input\n",
    "word_embeddings = bert_model.get_input_embeddings()\n",
    "max_seq_len = 30\n",
    "\n",
    "text = df['reviewText'].iloc[0]\n",
    "token_ids = tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len=max_seq_len)\n",
    "x_in = word_embeddings(torch.tensor(token_ids, requires_grad=False).long())\n",
    "x_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## encode sequence with LSTM\n",
    "bert_dim = 768\n",
    "input_dim = bert_dim\n",
    "hidden_dim = seq_emb\n",
    "output_dim = seq_emb\n",
    "n_layers = max_seq_len\n",
    "batch_size = 1\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers=max_seq_len, device=device)\n",
    "h = model.init_hidden(batch_size)\n",
    "#if model_type == \"LSTM\":\n",
    "h = tuple([e.data for e in h])\n",
    "len(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, h = model(x_in.unsqueeze(0).float(), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1, 64])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(h))\n",
    "h[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mt",
   "language": "python",
   "name": ".venv-mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
