{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "import random \n",
    "\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#nltk.download()\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "#import more_itertools as mit\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "CPU times: user 2.07 s, sys: 488 ms, total: 2.56 s\n",
      "Wall time: 9.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not bert_loaded:\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_tokenizer.add_special_tokens({\"unk_token\": '[UNK]', 'cls_token': '[CLS]', \n",
    "                                       'pad_token':'[PAD]', 'sep_token':'[SEP]'})\n",
    "    print(len(bert_tokenizer))\n",
    "    assert bert_tokenizer.cls_token == '[CLS]'\n",
    "    bert_tokenizer.sep_token_id\n",
    "    \n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True,\n",
    "                                            output_attentions=True)\n",
    "    bert_model.resize_token_embeddings(len(bert_tokenizer))\n",
    "    \n",
    "    bert_loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta_Computers.json.gz',\n",
       " 'Electronics_5.json.gz',\n",
       " 'Books_5.json.gz',\n",
       " 'one_week.tar.gz',\n",
       " 'contentdata.tar.gz',\n",
       " 'books-pickle']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df4.pkl',\n",
       " 'df.json',\n",
       " 'df2.pkl',\n",
       " 'df5.pkl',\n",
       " 'item_stats.pkl',\n",
       " 'df3.pkl',\n",
       " 'df0.pkl',\n",
       " 'df1.pkl',\n",
       " 'pytorch_model.bin',\n",
       " 'user_stats.pkl',\n",
       " 'df.pkl',\n",
       " 'config.json',\n",
       " 'encoded_text.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dirpath, dirnames, filenames) = next(os.walk('../datasets/books-pickle/'), (None, None, []))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_path = '../datasets/Books_5.json.gz'\n",
    "pkl_path = '../datasets/books-pickle/'\n",
    "\n",
    "with open(pkl_path + \"df.pkl\", 'rb') as fin:\n",
    "    df = pickle.load(fin)\n",
    "\n",
    "with open(pkl_path + \"user_stats.pkl\", 'rb') as fin:\n",
    "    user_dict = pickle.load(fin)\n",
    "    \n",
    "with open(pkl_path + \"item_stats.pkl\", 'rb') as fin:\n",
    "    item_dict = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-03-30</td>\n",
       "      <td>A1REUF3A1YCPHM</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>A story children will love and learn from The ...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>AVP0HXC9FG790</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars The kids loved it!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>A324TTUBKTN73A</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars My students (3 &amp; 4 year olds) loved...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>A2RE7WG349NV5D</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars LOVE IT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>A32B7QIUDQCD0E</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>Five Stars Great!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified reviewTime      reviewerID      itemID  \\\n",
       "0        5     False 2005-03-30  A1REUF3A1YCPHM  0001713353   \n",
       "1        5      True 2016-06-20   AVP0HXC9FG790  0001713353   \n",
       "2        5      True 2016-01-24  A324TTUBKTN73A  0001713353   \n",
       "3        5     False 2015-07-09  A2RE7WG349NV5D  0001713353   \n",
       "4        5      True 2015-01-18  A32B7QIUDQCD0E  0001713353   \n",
       "\n",
       "                                          reviewText  reviewWords  \n",
       "0  A story children will love and learn from The ...          170  \n",
       "1                      Five Stars The kids loved it!            6  \n",
       "2  Five Stars My students (3 & 4 year olds) loved...           15  \n",
       "3                                 Five Stars LOVE IT            4  \n",
       "4                                  Five Stars Great!            3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame.from_dict(user_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>m_rating</th>\n",
       "      <th>m_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0334855HN6E38CXWXZR</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0790722OCX87RKL2J3T</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100JBBLCC0NUC</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A101OKMJFCIWYH</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1022R52JDJVMA</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      n_reviews  m_rating  m_words\n",
       "A0334855HN6E38CXWXZR          1       5.0     12.0\n",
       "A0790722OCX87RKL2J3T          1       5.0     71.0\n",
       "A100JBBLCC0NUC                1       5.0     27.0\n",
       "A101OKMJFCIWYH                2       5.0     26.0\n",
       "A1022R52JDJVMA                1       5.0     58.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.DataFrame.from_dict(item_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_seq(tokens, tokenizer, max_len=512):\n",
    "    if len(tokens) < max_len:\n",
    "        tokens=tokens[:-1]\n",
    "        n = max_len - len(tokens) - 1\n",
    "        tokens += n * [tokenizer.pad_token]\n",
    "    elif len(tokens) > max_len:\n",
    "        tokens=tokens[:max_len-1]\n",
    "    else:\n",
    "        return tokens\n",
    "    \n",
    "    tokens.append(tokenizer.sep_token)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def tokenize_text_to_ids(text, tokenizer, sent_tokenize, max_len=512):\n",
    "    sents = sent_tokenize(text)\n",
    "    tokens = []\n",
    "    tokens.append(bert_tokenizer.cls_token)\n",
    "    for s in sents:\n",
    "        tokens.extend(bert_tokenizer.tokenize(s))\n",
    "        tokens.append(bert_tokenizer.sep_token)\n",
    "    \n",
    "    tokens = truncate_seq(tokens, tokenizer, max_len)\n",
    "    \n",
    "    assert len(tokens) == max_len\n",
    "    \n",
    "    return bert_tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = bert_model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options for Encoding Sentences: \n",
    "1. Bert Embeddings (Raw): tokenise text and apply Bert Embeddings, no further processing [batch_size x seq_len x dim_e] => subsequent (sophisticated) Encoder should produce sentence representation [batch_size x dim_s]\n",
    "2. Last Hidden States: sequence encoded by Bert, powerful processing [batch_size x seq_len x dim_e] => subsequent (simple) Encoder produce sentence representation [batch_size x dim_s]\n",
    "3. Average over Last Hidden States: seq. encoded by Bert and average in the end to yield sentence representation [batch_size x dim_s]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.9 ms, sys: 240 µs, total: 10.1 ms\n",
      "Wall time: 10.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_elems=2\n",
    "encoded_in = [bert_tokenizer.encode(sent, max_length=30, add_special_tokens=True, pad_to_max_length=True) for sent in list(df['reviewText'])[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = torch.tensor(encoded_in, requires_grad=False).long()\n",
    "#outputs = bert_model(x_in)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT for Sentence Encoding\n",
    "\n",
    "1. Use last hidden state of CLS \n",
    "2. Use average of last hidden states of all tokens \n",
    "3. Use average over multiple hidden layers (A) for CLS or (B) for all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(df, tokenizer, sent_tokenize, bert_model, max_len=50, batch_size=2, method='cls_last', n=None):\n",
    "\n",
    "    encoded_text = {}\n",
    "    start_idx = 0\n",
    "    stop_idx = batch_size\n",
    "\n",
    "    while(start_idx < len(df)):\n",
    "\n",
    "        if stop_idx > len(df):\n",
    "            stop_idx = len(df)\n",
    "\n",
    "        tokens = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text\n",
    "                  in list(df['reviewText'])[start_idx:stop_idx]]\n",
    "\n",
    "        x_in = torch.tensor(tokens, requires_grad=False, device=device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            last_hidden, pooled_out, hidden_outs, attention_weights = bert_model(x_in)\n",
    "\n",
    "        assert last_hidden.shape[0] == batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_last_n\n",
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "batch_size=2\n",
    "max_len=50\n",
    "method='sum_last_n'\n",
    "n = 4\n",
    "\n",
    "encoded_text = {}\n",
    "start_idx = 0\n",
    "stop_idx = batch_size\n",
    "\n",
    "\n",
    "##BERT for Feature-Extraction\n",
    "\n",
    "#tokenize\n",
    "tokens = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text\n",
    "          in list(df['reviewText'])[start_idx:stop_idx]]\n",
    "x_in = torch.tensor(tokens, requires_grad=False).long()\n",
    "\n",
    "#model forward pass\n",
    "with torch.no_grad():\n",
    "    last_hidden, pooled_out, hidden_outs, attention_weights = bert_model(x_in)\n",
    "    \n",
    "#save tensor of encoded text into separate dictionary\n",
    "keys = range(start_idx, stop_idx+1)\n",
    "\n",
    "    \n",
    "if 'pooled_out' == method:\n",
    "    x_out = pooled_out # batch_size x dim_emb\n",
    "elif 'cls_last' == method:\n",
    "    #take the embedding of CLS token of last hidden layer\n",
    "    x_out = last_hidden[:,0,:] # batch_size x dim_emb\n",
    "elif 'pool_all_last' == method:\n",
    "    #average embeddings of last hidden layer of all tokens\n",
    "    x_out = torch.mean(last_hidden, dim=1)\n",
    "elif 'pool_cls_n'==method:\n",
    "    # and n != None\n",
    "    x_out = torch.mean(torch.cat([hidden[:,0,:].unsqueeze(1) for hidden in hidden_outs[-n:]], dim=1), dim=1)\n",
    "elif 'pool_last_n'==method:\n",
    "    #average embeddings of last N hidden layers of all tokens\n",
    "    x_out = torch.mean(torch.cat(hidden_outs[-n:], dim=1), dim=1)\n",
    "elif 'sum_last_n'==method and n:\n",
    "    #sum embeddings of last N hidden layers of all tokens\n",
    "    x_out = torch.sum(torch.cat(hidden_outs[-n:], dim=1), dim=1)\n",
    "    #sum last four hidden => 95.9 F1 on dev set for NER\n",
    "elif 'sum_all'==method and n:\n",
    "    x_out = torch.sum(torch.cat(hidden_outs, dim=1), dim=1)\n",
    "\n",
    "print(method)\n",
    "print(x_out.shape)\n",
    "encoded_text = {**encoded_text, **dict(zip(keys, x_out))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Encoding Text..\")\n",
    "\n",
    "bert_model.to(device)\n",
    "\n",
    "encoded_text = {}\n",
    "start_idx = 0\n",
    "stop_idx = batch_size\n",
    "\n",
    "while(start_idx < len(df)):\n",
    "\n",
    "    if stop_idx > len(df):\n",
    "        stop_idx = len(df)\n",
    "\n",
    "    encoded_in = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text\n",
    "              in list(df['reviewText'])[start_idx:stop_idx]]\n",
    "\n",
    "    encoded_in = torch.tensor(encoded_in, requires_grad=False, device=device).long()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden, pooled_out = bert_model(encoded_in)\n",
    "\n",
    "    assert last_hidden.shape[0] == batch_size\n",
    "\n",
    "    #save tensor of encoded text into separate dictionary\n",
    "    keys = range(start_idx, stop_idx+1)\n",
    "    encoded_text = {**encoded_text, **dict(zip(keys, last_hidden))}\n",
    "\n",
    "    start_idx += batch_size\n",
    "    stop_idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_representations(user_reviews, item_reviews, method='avg_items'):\n",
    "    user_repr = {}\n",
    "    for u in user_reviews.keys():\n",
    "        \n",
    "        if 'avg_items' == method:\n",
    "            stacked_reviews = torch.stack([item_reviews[i] for i in user_reviews[u].keys()])\n",
    "            #print(stacked_user_reviews.shape)\n",
    "            user_repr[u] = torch.mean(stacked_reviews, dim=0)\n",
    "        elif 'avg_items_user' == method:\n",
    "            stacked_reviews = torch.stack([item_reviews[i] for i in user_reviews[u].keys()])\n",
    "            stacked_reviews_user = torch.stack([user_reviews[u][r] for r in user_reviews[u].keys()])\n",
    "            user_repr[u] = torch.mean(stacked_reviews+stacked_reviews_user, dim=0)\n",
    "    \n",
    "    return user_repr\n",
    "\n",
    "\n",
    "def create_toy_representations(seq_emb=64, item_ids=range(100), user_ids = range(20), method='avg_items'):\n",
    "        \n",
    "    item_reviews = {}\n",
    "\n",
    "    for i in item_ids:\n",
    "        item_reviews[i] = torch.stack([torch.randn(seq_emb)] * random.randint(5,10), dim=0)\n",
    "        item_reviews[i] = torch.mean(item_reviews[i], dim=0)\n",
    "    \n",
    "    \n",
    "    user_reviews = {}\n",
    "    \n",
    "    for i in user_ids:\n",
    "        user_reviews[i] = {}\n",
    "        for r in random.sample(list(item_reviews.keys()), random.randint(5,10)):\n",
    "        #user_reviews[i] = dict(zip(random.sample(list(item_reviews.keys()), random.randint(5,10)), torch.randn(seq_emb)))\n",
    "            user_reviews[i][r] = torch.randn(seq_emb)\n",
    "            \n",
    "    return item_reviews, user_reviews, create_user_representations(user_reviews, item_reviews, method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_reviews, user_reviews, user_repr_avg = create_toy_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_repr_ui = create_user_representations(user_reviews, item_reviews, method='avg_items_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34152778796851635\n",
      "0.06405663349608343\n"
     ]
    }
   ],
   "source": [
    "cos = []\n",
    "for k in list(user_reviews[0].keys()):\n",
    "    cos.append(cosine_similarity(user_repr_avg[0].unsqueeze(0), item_reviews[k].unsqueeze(0)).item())\n",
    "    \n",
    "print(np.mean(cos))\n",
    "print(np.std(cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21049505844712257\n",
      "0.08154537465453288\n"
     ]
    }
   ],
   "source": [
    "cos = []\n",
    "for k in list(user_reviews[0].keys()):\n",
    "    cos.append(cosine_similarity(user_repr_ui[0].unsqueeze(0), item_reviews[k].unsqueeze(0)).item())\n",
    "    \n",
    "print(np.mean(cos))\n",
    "print(np.std(cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(user_repr_ui[0].unsqueeze(0), user_repr_ui[0].unsqueeze(0)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, device, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device)\n",
    "        return hidden\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, device, drop_prob=0.2, bi=False):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob, bidirectional=bi)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device))\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode user with GRU\n",
    "seq_emb = 64\n",
    "input_dim = seq_emb\n",
    "hidden_dim = seq_emb\n",
    "output_dim = seq_emb\n",
    "\n",
    "stacked_reviews = torch.stack([item_reviews[i] for i in user_reviews[0].keys()])\n",
    "n_layers = stacked_reviews.shape[0]\n",
    "batch_size = 1\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "model = GRUNet(input_dim, hidden_dim, output_dim, n_layers, device)\n",
    "h = model.init_hidden(batch_size)\n",
    "#if model_type == \"GRU\":\n",
    "h = h.data\n",
    "        \n",
    "out, h = model(stacked_reviews.unsqueeze(0).float(), h)\n",
    "print(len(h))\n",
    "user_repr_gru = h[-1].detach()\n",
    "user_repr_gru.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Sequence Encoding - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep input\n",
    "word_embeddings = bert_model.get_input_embeddings()\n",
    "max_seq_len = 30\n",
    "\n",
    "text = df['reviewText'].iloc[0]\n",
    "token_ids = tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len=max_seq_len)\n",
    "x_in = word_embeddings(torch.tensor(token_ids, requires_grad=False).long())\n",
    "x_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## encode sequence with LSTM\n",
    "bert_dim = 768\n",
    "input_dim = bert_dim\n",
    "hidden_dim = seq_emb\n",
    "output_dim = seq_emb\n",
    "n_layers = max_seq_len\n",
    "batch_size = 1\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers=max_seq_len, device=device)\n",
    "h = model.init_hidden(batch_size)\n",
    "#if model_type == \"LSTM\":\n",
    "h = tuple([e.data for e in h])\n",
    "len(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, h = model(x_in.unsqueeze(0).float(), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1, 64])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(h))\n",
    "h[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mt",
   "language": "python",
   "name": ".venv-mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
