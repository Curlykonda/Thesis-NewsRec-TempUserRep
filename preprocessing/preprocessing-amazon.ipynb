{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#nltk.download()\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "#import more_itertools as mit\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import torch\n",
    "#from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "CPU times: user 2.16 s, sys: 500 ms, total: 2.66 s\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not bert_loaded:\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_tokenizer.add_special_tokens({\"unk_token\": '[UNK]', 'cls_token': '[CLS]', \n",
    "                                       'pad_token':'[PAD]', 'sep_token':'[SEP]'})\n",
    "    print(len(bert_tokenizer))\n",
    "    assert bert_tokenizer.cls_token == '[CLS]'\n",
    "    bert_tokenizer.sep_token_id\n",
    "    \n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True,\n",
    "                                            output_attentions=True)\n",
    "    bert_model.resize_token_embeddings(len(bert_tokenizer))\n",
    "    \n",
    "    bert_loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path, chunk_size=20000):\n",
    "    i = 0\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        for l in f:\n",
    "            yield json.loads(l.strip())\n",
    "            i+=1\n",
    "            if i == chunk_size:\n",
    "                break\n",
    "def parse2(f):\n",
    "    for l in f:\n",
    "        yield json.loads(l.strip())        \n",
    "            \n",
    "def getDF(path, chunk_size):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path, chunk_size):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def getDF_chunks(path, chunk_size, pkl_path, max_chunks=4):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    df_chunks = 0\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        for d in parse2(f):\n",
    "            df[i] = d\n",
    "            i+=1\n",
    "            \n",
    "            if i == chunk_size:\n",
    "                df = pd.DataFrame.from_dict(df, orient='index')\n",
    "                #preprocessing(df)\n",
    "                df.to_pickle(pkl_path + \"df\" + str(df_chunks) +\".pkl\")\n",
    "                df = {}\n",
    "                i = 0\n",
    "                df_chunks +=1\n",
    "    return df_chunks, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!wget http://deepyeti.ucsd.edu/jianmo/amazon/sample/meta_Computers.json.gz\\ndf = getDF(\\'meta_Computers.json.gz\\')\\nlen(df)\\n### remove rows with unformatted title (i.e. some \\'title\\' may still contain html style content)\\n\\ndf3 = df.fillna(\\'\\')\\ndf4 = df3[df3.title.str.contains(\\'getTime\\')] # unformatted rows\\ndf5 = df3[~df3.title.str.contains(\\'getTime\\')] # filter those unformatted rows\\nprint(\"Unformatted rows: {} ({:.2f}%)\".format(len(df4), len(df4)/len(df3)*100))\\nprint(\"Remaining rows: {}\".format(len(df5)))\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/sample/meta_Computers.json.gz\n",
    "df = getDF('meta_Computers.json.gz')\n",
    "len(df)\n",
    "### remove rows with unformatted title (i.e. some 'title' may still contain html style content)\n",
    "\n",
    "df3 = df.fillna('')\n",
    "df4 = df3[df3.title.str.contains('getTime')] # unformatted rows\n",
    "df5 = df3[~df3.title.str.contains('getTime')] # filter those unformatted rows\n",
    "print(\"Unformatted rows: {} ({:.2f}%)\".format(len(df4), len(df4)/len(df3)*100))\n",
    "print(\"Remaining rows: {}\".format(len(df5)))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta_Computers.json.gz',\n",
       " 'Electronics_5.json.gz',\n",
       " 'Books_5.json.gz',\n",
       " 'one_week.tar.gz',\n",
       " 'contentdata.tar.gz',\n",
       " 'books-pickle']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text2(sent, remove_stop_word=False, stemming=False, stemmer=None):\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    #tokenise, punctuation, lower-case\n",
    "    tokens = [word.lower() for sent in sent_tokenize(sent) for word in word_tokenize(sent) if word.isalpha()]\n",
    "    \n",
    "    if remove_stop_word:\n",
    "        #filter stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    if stemming:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        \n",
    "    #locating and correcting common typos & misspellings\n",
    "        \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def clean_text(sent, tokenizer, stop_words=None, stemmer=None):\n",
    "\n",
    "    # tokenise & punctuation\n",
    "    tokens = [word for word in tokenizer.tokenize(sent) if word.isalpha()]\n",
    "\n",
    "    if not stop_words == None:\n",
    "        #stop_words = list(set(stopwords.words('english')))\n",
    "        # filter stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    if not stemmer == None:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # locating and correcting common typos & misspellings\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def clean_df(df, drop_org_reviews=False):\n",
    "    ### remove rows with unformatted title (i.e. some 'title' may still contain html style content)\n",
    "\n",
    "    df = df.fillna('')\n",
    "    df = df.drop(['reviewerName', 'style', 'vote', 'image'], axis=1)\n",
    "    \n",
    "    #reformat timestamp\n",
    "    df['reviewTime'] = df['unixReviewTime'].apply(lambda x: pd.Timestamp(x, unit='s'))\n",
    "    df = df.drop('unixReviewTime', axis=1)\n",
    "    \n",
    "    #rename columns\n",
    "    df = df.rename(columns={'asin':'itemID'})\n",
    "    \n",
    "    #aggregate text\n",
    "    df['reviewText'] = df['summary'] + \" \" + df['reviewText']\n",
    "    df = df.drop('summary', axis=1)\n",
    "    \n",
    "    ## convert to other (smaller) datatype\n",
    "    df['overall'] = df['overall'].astype('int32')\n",
    "    \n",
    "    #clean text\n",
    "    if 'cleanedText' not in df.columns:\n",
    "        print(\"Cleaning Text..\")\n",
    "        df['reviewWords'] = df['reviewText'].apply(lambda x: len(clean_text(x, bert_tokenizer)))\n",
    "        if drop_org_reviews:\n",
    "            df = df.drop('reviewText', axis=1)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def aggregate_info(df, user_d, items_d):\n",
    "    \n",
    "    added = 0\n",
    "    updated = 0\n",
    "    \n",
    "    print(\"Aggregating User Stats..\")\n",
    "    for u, group in tqdm(df.groupby('reviewerID')):\n",
    "        \n",
    "        if u not in user_d:\n",
    "            user_d[u] = {}\n",
    "            user_d[u]['n_reviews'] = group['itemID'].count()\n",
    "            user_d[u]['m_rating'] = group['overall'].mean()\n",
    "            user_d[u]['m_words'] = group['reviewWords'].mean()\n",
    "            added+=1\n",
    "        else:\n",
    "            user_d[u]['n_reviews'] += group['itemID'].count()\n",
    "            user_d[u]['m_rating'] = np.mean([user_d[u]['m_rating'], group['overall'].mean()])\n",
    "            user_d[u]['m_words'] = np.mean([user_d[u]['m_words'], group['reviewWords'].mean()])\n",
    "            updated+=1\n",
    "\n",
    "    print(\"Total users: %.0f\" % len(user_d.keys()))\n",
    "    print(\"Added: %.0f\" % added)\n",
    "    print(\"Updated: %.0f\" % updated)\n",
    "     \n",
    "                \n",
    "    #count reviews per item\n",
    "    added = 0\n",
    "    updated = 0\n",
    "    \n",
    "    print(\"Aggregating Item Stats..\")\n",
    "    for item, group in tqdm(df.groupby('itemID')):\n",
    "    \n",
    "        if item not in items_d:\n",
    "            items_d[item] = {}\n",
    "            items_d[item]['n_reviews'] = group['reviewerID'].count()\n",
    "            items_d[item]['m_rating'] = group['overall'].mean()\n",
    "            items_d[item]['m_words'] = group['reviewWords'].mean()\n",
    "            added+=1\n",
    "        else:\n",
    "            items_d[item]['n_reviews'] += group['reviewerID'].count()\n",
    "            items_d[item]['m_rating'] = np.mean([items_d[item]['m_rating'], group['overall'].mean()])\n",
    "            items_d[item]['m_words'] = np.mean([items_d[item]['m_words'], group['reviewWords'].mean()])\n",
    "            updated+=1\n",
    "    \n",
    "    print(\"Total items: %.0f\" % len(items_d.keys()))\n",
    "    print(\"Added: %.0f\" % added)\n",
    "    print(\"Updated: %.0f\" % updated)  \n",
    "    \n",
    "    return user_d, items_d\n",
    "\n",
    "\n",
    "def preprocessDF_chunks(path, chunk_size, pkl_path, drop_org_reviews=False, max_chunks=4):\n",
    "    i = 0\n",
    "    data = {}\n",
    "    n_chunks = 0\n",
    "    \n",
    "    #aggreated info\n",
    "    user_dict = {}\n",
    "    item_dict = {}\n",
    "    \n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        print(\"Start reading: {}\".format(path))\n",
    "        for d in parse2(f):\n",
    "            data[i] = d\n",
    "            i+=1\n",
    "            \n",
    "            #if i == 10:\n",
    "            #    print(d)\n",
    "            \n",
    "            if i == chunk_size:\n",
    "                print(\"Processing Chunk {}\".format(n_chunks))\n",
    "                \n",
    "                #print(list(data.items())[:2])\n",
    "                \n",
    "                df = pd.DataFrame.from_dict(data, orient='index')\n",
    "                #preprocessing\n",
    "                df = clean_df(df, drop_org_reviews)\n",
    "                \n",
    "                #aggregate info\n",
    "                user_dict, item_dict = aggregate_info(df, user_dict, item_dict)\n",
    "                \n",
    "                #save cleaned dataframe\n",
    "                df.to_pickle(pkl_path + \"df\" + str(n_chunks) +\".pkl\")\n",
    "                \n",
    "                #save stats\n",
    "                with open(pkl_path + \"user_stats.pkl\", 'wb') as fout:\n",
    "                    pickle.dump(user_dict, fout)\n",
    "                with open(pkl_path + \"item_stats.pkl\", 'wb') as fout:\n",
    "                    pickle.dump(item_dict, fout)\n",
    "                \n",
    "                i = 0\n",
    "                data = {}\n",
    "                n_chunks +=1\n",
    "                print(\"\\n\")\n",
    "                \n",
    "            if max_chunks < n_chunks:\n",
    "                break\n",
    "                \n",
    "    return n_chunks, i, user_dict, item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df2.pkl',\n",
       " 'item_stats.pkl',\n",
       " 'df3.pkl',\n",
       " 'df0.pkl',\n",
       " 'df1.pkl',\n",
       " 'user_stats.pkl',\n",
       " 'df.pkl',\n",
       " 'encoded_text.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dirpath, dirnames, filenames) = next(os.walk('../datasets/books-pickle/'), (None, None, []))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading: ../datasets/Books_5.json.gz\n",
      "Processing Chunk 0\n",
      "Cleaning Text..\n",
      "Aggregating User Stats..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17720/17720 [00:12<00:00, 1408.08it/s]\n",
      "100%|██████████| 160/160 [00:00<00:00, 1167.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 17720\n",
      "Added: 17720\n",
      "Updated: 0\n",
      "Aggregating Item Stats..\n",
      "Total items: 160\n",
      "Added: 160\n",
      "Updated: 0\n",
      "\n",
      "\n",
      "Processing Chunk 1\n",
      "Cleaning Text..\n",
      "Aggregating User Stats..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16818/16818 [00:11<00:00, 1453.64it/s]\n",
      "100%|██████████| 122/122 [00:00<00:00, 1310.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 31920\n",
      "Added: 14200\n",
      "Updated: 2618\n",
      "Aggregating Item Stats..\n",
      "Total items: 278\n",
      "Added: 118\n",
      "Updated: 4\n",
      "\n",
      "\n",
      "Processing Chunk 2\n",
      "Cleaning Text..\n",
      "Aggregating User Stats..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18337/18337 [00:12<00:00, 1463.60it/s]\n",
      "100%|██████████| 144/144 [00:00<00:00, 1467.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 47970\n",
      "Added: 16050\n",
      "Updated: 2287\n",
      "Aggregating Item Stats..\n",
      "Total items: 421\n",
      "Added: 143\n",
      "Updated: 1\n",
      "\n",
      "\n",
      "Processing Chunk 3\n",
      "Cleaning Text..\n",
      "Aggregating User Stats..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17539/17539 [00:12<00:00, 1363.31it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 1410.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 61018\n",
      "Added: 13048\n",
      "Updated: 4491\n",
      "Aggregating Item Stats..\n",
      "Total items: 659\n",
      "Added: 238\n",
      "Updated: 2\n",
      "\n",
      "\n",
      "Processing Chunk 4\n",
      "Cleaning Text..\n",
      "Aggregating User Stats..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18338/18338 [00:13<00:00, 1355.94it/s]\n",
      "100%|██████████| 172/172 [00:00<00:00, 1393.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 76043\n",
      "Added: 15025\n",
      "Updated: 3313\n",
      "Aggregating Item Stats..\n",
      "Total items: 829\n",
      "Added: 170\n",
      "Updated: 2\n",
      "\n",
      "\n",
      "Processing Chunk 5\n",
      "Cleaning Text..\n",
      "Aggregating User Stats..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17903/17903 [00:11<00:00, 1495.67it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 1385.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 91048\n",
      "Added: 15005\n",
      "Updated: 2898\n",
      "Aggregating Item Stats..\n",
      "Total items: 934\n",
      "Added: 105\n",
      "Updated: 2\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-917300964a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mn_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessDF_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_org_reviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"df1.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"###############\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "books_path = '../datasets/Books_5.json.gz'\n",
    "chunk_size=20000\n",
    "pkl_path = '../datasets/books-pickle/'\n",
    "\n",
    "user_dict = {}\n",
    "item_dict = {}\n",
    "\n",
    "dev=False\n",
    "\n",
    "if dev:\n",
    "    df = getDF(books_path, chunk_size=10000)\n",
    "    df = clean_df(df)\n",
    "    user_dict, item_dict = aggregate_info(df, user_dict, item_dict)\n",
    "else:\n",
    "    n_chunks, i, user_dict, item_dict = preprocessDF_chunks(books_path, chunk_size, pkl_path, drop_org_reviews=True, max_chunks=5)\n",
    "    df = pickle.load(pkl_path + \"df1.pkl\")\n",
    "    \n",
    "print(\"###############\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8908"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique reviewers: 8908\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique reviewers: {}\".format(df['reviewerID'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8908/8908 [00:22<00:00, 396.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 128 ms, total: 22.4 s\n",
      "Wall time: 22.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "u_users = list(df['reviewerID'].unique())\n",
    "for u in tqdm(u_users):\n",
    "    n_re = df[df[\"reviewerID\"] == u][\"itemID\"].count()\n",
    "    if u not in user_dict:\n",
    "        user_dict[u] = {}\n",
    "        user_dict[u]['n_reviews'] = n_re\n",
    "    else:\n",
    "        user_dict[u]['n_reviews'] += n_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"reviewerID\"] == 'A1SDAYRVRR62ZH']['itemID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(user_dict.values()['n_reviews'], bins=[1,2,4,6,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, val in df.groupby(\"itemID\")['reviewerID']:\n",
    "    #print(name + \" \" + str(val.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemID\n",
       "0001844423    2753\n",
       "0002005549     778\n",
       "0001720392     774\n",
       "0001951076     681\n",
       "0002051850     603\n",
       "0001945424     556\n",
       "0001384198     451\n",
       "0001381733     317\n",
       "0002180618     302\n",
       "0002008599     210\n",
       "Name: reviewerID, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"itemID\")['reviewerID'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Reviews per Item')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.groupby(\"itemID\")['reviewerID'].count())\n",
    "plt.title(\"Reviews per Item\")\n",
    "#plt.xaxis(\"# Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 4.50\n",
      "Median: 5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = plt.hist(df['overall'], bins=[1,2,3,4,5,6], density=True)\n",
    "plt.title('Ratings')\n",
    "print(\"Mean: %.2f\" % df['overall'].mean())\n",
    "print(\"Median: %.1f\" % df['overall'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenise content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477\n",
      "Maybe It's Not As Bad As You Think So, you think you have problems? Things could be worse and this clever book can prove it. The king starts out with a problem. The mice are eating his cheese. The more he tries to fix the problem, the worse it gets. The king finally arranges to bring back the mice when he comes to the realization that his original dilemma  wasn't so intolerable after all. The solution requires cooperation from the king and the mice. It involves the cheese.\n"
     ]
    }
   ],
   "source": [
    "row = 10 \n",
    "\n",
    "sent = df['reviewText'].iloc[row]\n",
    "\n",
    "print(len(sent))\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Maybe It's Not As Bad As You Think So, you think you have problems?\",\n",
       " 'Things could be worse and this clever book can prove it.',\n",
       " 'The king starts out with a problem.',\n",
       " 'The mice are eating his cheese.',\n",
       " 'The more he tries to fix the problem, the worse it gets.',\n",
       " \"The king finally arranges to bring back the mice when he comes to the realization that his original dilemma  wasn't so intolerable after all.\",\n",
       " 'The solution requires cooperation from the king and the mice.',\n",
       " 'It involves the cheese.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(set(stopwords.words('english')))\n",
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "tokens = [word for word in bert_tokenizer.tokenize(sent) if word.isalpha()]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "#tokenise, punctuation, lower-case\n",
    "tokens = [word.lower() for sent in sent_tokenize(sent) for word in word_tokenize(sent) if word.isalpha()]\n",
    "\n",
    "#filter stop words\n",
    "#tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mayb it not as bad as you think so you think you have problem thing could be wors and thi clever book can prove it the king start out with a problem the mice are eat hi chees the more he tri to fix the problem the wors it get the king final arrang to bring back the mice when he come to the realiz that hi origin dilemma wa so intoler after all the solut requir cooper from the king and the mice it involv the chees'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming?\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(token) for token in tokens]\n",
    "\" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall        5\n",
       "verified       5\n",
       "reviewTime     5\n",
       "reviewerID     5\n",
       "itemID         5\n",
       "reviewText     5\n",
       "cleanedText    5\n",
       "reviewWords    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_length = df['reviewText'].apply(lambda x: len(x))\n",
    "df[df['reviewText'].apply(lambda x: len(x)) < 10].count()\n",
    "\n",
    "#plt.hist(review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_bert(text, tokenizer):\n",
    "    return tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['let', \"'\", 's', 'see', 'how', 'text', 'is', 'handled', 'if', 'there', \"'\", 're', 'errors', '!', '!']\n",
      "[2292, 1005, 1055, 2156, 2129, 3793, 2003, 8971, 2065, 2045, 1005, 2128, 10697, 999, 999]\n",
      "['let', \"'\", 's', 'see', 'how', 'tx', '##et', 'is', 'han', '##led', 'if', 'there', \"'\", 're', 'errors', '!', '!']\n",
      "[2292, 1005, 1055, 2156, 2129, 19067, 3388, 2003, 7658, 3709, 2065, 2045, 1005, 2128, 10697, 999, 999]\n",
      "[101, 2292, 1005, 1055, 2156, 2129, 19067, 3388, 2003, 7658, 3709, 2065, 2045, 1005, 2128, 10697, 999, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sent = \"Let's see how text is handled if there're errors!!\"\n",
    "print(clean_text_bert(sent, bert_tokenizer))\n",
    "print(bert_tokenizer.convert_tokens_to_ids(clean_text_bert(sent, bert_tokenizer)))\n",
    "\n",
    "sent = \"Let's see how txet is hanled if there're errors!!\"\n",
    "print(clean_text_bert(sent, bert_tokenizer))\n",
    "print(bert_tokenizer.convert_tokens_to_ids(clean_text_bert(sent, bert_tokenizer)))\n",
    "\n",
    "print(bert_tokenizer.encode(sent, max_length=30, add_special_tokens=True, pad_to_max_length=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 104 ms, total: 22.9 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "use_both=False\n",
    "use_bert=True\n",
    "\n",
    "if use_both:\n",
    "    df['cleanedTextBert'] = df['reviewText'].apply(lambda x: clean_text_bert(x, bert_tokenizer))\n",
    "    df['reviewWordsBert'] = df['cleanedTextBert'].apply(lambda x: len(x))\n",
    "    df['cleanedText'] = df['reviewText'].apply(lambda x: clean_text(x))\n",
    "    df['reviewWords'] = df['cleanedText'].apply(lambda x: len(x.split()))\n",
    "elif use_bert: \n",
    "    df['cleanedTextBert'] = df['reviewText'].apply(lambda x: clean_text_bert(x, bert_tokenizer))\n",
    "    df['reviewWordsBert'] = df['cleanedTextBert'].apply(lambda x: len(x))\n",
    "    '''\n",
    "    BertTokenizer keeps more (if not all) tokens of a review, \n",
    "    including things like stopwords or non-alphanumeric symbols,\n",
    "    which results in \"less\" cleaning and longer reviews \n",
    "    '''\n",
    "else: \n",
    "    df['cleanedText'] = df['reviewText'].apply(lambda x: clean_text(x))\n",
    "    df['reviewWords'] = df['cleanedText'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall            6\n",
       "verified           6\n",
       "reviewTime         6\n",
       "reviewerID         6\n",
       "itemID             6\n",
       "reviewText         6\n",
       "cleanedText        6\n",
       "reviewWords        6\n",
       "cleanedTextBert    6\n",
       "reviewWordsBert    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['cleanedText'].apply(lambda x: len(x)) < 10].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall            3\n",
       "verified           3\n",
       "reviewTime         3\n",
       "reviewerID         3\n",
       "itemID             3\n",
       "reviewText         3\n",
       "cleanedText        3\n",
       "reviewWords        3\n",
       "cleanedTextBert    3\n",
       "reviewWordsBert    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['cleanedText'].apply(lambda x: len(x)) < 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall            0\n",
       "verified           0\n",
       "reviewTime         0\n",
       "reviewerID         0\n",
       "itemID             0\n",
       "reviewText         0\n",
       "cleanedText        0\n",
       "reviewWords        0\n",
       "cleanedTextBert    0\n",
       "reviewWordsBert    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['reviewWordsBert'] < 2].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>cleanedText</th>\n",
       "      <th>reviewWords</th>\n",
       "      <th>cleanedTextBert</th>\n",
       "      <th>reviewWordsBert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>A18WUVMHPTVYQ8</td>\n",
       "      <td>0001844423</td>\n",
       "      <td>100% 100%</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[100, %, 100, %]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>A197527ILE0LL8</td>\n",
       "      <td>0001844423</td>\n",
       "      <td>5stars 5stars</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[5, ##star, ##s, 5, ##star, ##s]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>A2PU9Z67Q8VRRM</td>\n",
       "      <td>0001713256</td>\n",
       "      <td>A+ A+</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[a, +, a, +]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      overall  verified reviewTime      reviewerID      itemID     reviewText  \\\n",
       "4813        5      True 2017-08-30  A18WUVMHPTVYQ8  0001844423      100% 100%   \n",
       "4982        5      True 2016-12-29  A197527ILE0LL8  0001844423  5stars 5stars   \n",
       "9967        5     False 2016-06-20  A2PU9Z67Q8VRRM  0001713256          A+ A+   \n",
       "\n",
       "     cleanedText  reviewWords                   cleanedTextBert  \\\n",
       "4813                        0                  [100, %, 100, %]   \n",
       "4982                        0  [5, ##star, ##s, 5, ##star, ##s]   \n",
       "9967                        0                      [a, +, a, +]   \n",
       "\n",
       "      reviewWordsBert  \n",
       "4813                4  \n",
       "4982                6  \n",
       "9967                4  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['cleanedText'].apply(lambda x: len(x)) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['reviewWords'] = df['cleanedText'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6405    4855\n",
       "7395    2882\n",
       "6406    2823\n",
       "6407    2451\n",
       "5936    2113\n",
       "7034    2010\n",
       "6408    1962\n",
       "8429    1874\n",
       "5230    1866\n",
       "6804    1637\n",
       "Name: reviewWords, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewWords'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6405    6009\n",
       "7395    3597\n",
       "6406    3585\n",
       "6407    3049\n",
       "7034    2840\n",
       "8429    2577\n",
       "5936    2503\n",
       "6408    2439\n",
       "5230    2319\n",
       "2846    2003\n",
       "Name: reviewWordsBert, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewWordsBert'].sort_values(ascending=False).head(10)\n",
    "#df['reviewWordsBert'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntokeniser = BertTokenizer.from_pretrained(\\'bert-base-uncased\\')\\nprint(tokeniser.convert_tokens_to_ids(tokeniser.tokenize(\"Let\\'s see all hidden-states and attentions on this text\")))\\n'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tokeniser = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(tokeniser.convert_tokens_to_ids(tokeniser.tokenize(\"Let's see all hidden-states and attentions on this text\")))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.969e+03, 6.780e+02, 1.750e+02, 4.800e+01, 2.200e+01, 8.000e+00,\n",
       "        1.000e+00, 4.000e+00, 0.000e+00, 3.000e+00]),\n",
       " array([   0.        ,  208.07777778,  416.15555556,  624.23333333,\n",
       "         832.31111111, 1040.38888889, 1248.46666667, 1456.54444444,\n",
       "        1664.62222222, 1872.7       , 2080.77777778]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_reviews_data = []\n",
    "m_words_data = []\n",
    "\n",
    "\n",
    "for u, values in user_dict.items():\n",
    "    n_reviews_data.append(values['n_reviews'])\n",
    "    m_words_data.append(values['m_words'])\n",
    "    \n",
    "#plt.hist(n_reviews_data)\n",
    "plt.hist(m_words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot distributions in with meaningful bin sizes/intervals, e.g. 1-2, 3-4, 5-7, >8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 100.0\n",
      "Median: 80.7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_reviews_data = []\n",
    "m_words_data = []\n",
    "\n",
    "\n",
    "for u, values in item_dict.items():\n",
    "    n_reviews_data.append(values['n_reviews'])\n",
    "    m_words_data.append(values['m_words'])\n",
    "    \n",
    "#plt.hist(n_reviews_data)\n",
    "plt.hist(m_words_data, density=True)\n",
    "print(\"Mean: %.1f\" % np.mean(m_words_data))\n",
    "print(\"Median: %.1f\" %np.median(m_words_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2292, 1005, 1055, 2156, 2035, 5023, 1011, 2163, 1998, 3086, 2015, 2006, 2023, 3793]\n"
     ]
    }
   ],
   "source": [
    "#bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(\"Let's see all hidden-states and attentions on this text\")))\n",
    "#print(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(\"Let's see all hidden-states? and attentions on this text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = bert_model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2023,\n",
       " 2003,\n",
       " 1037,\n",
       " 3231,\n",
       " 1011,\n",
       " 6251,\n",
       " 1010,\n",
       " 2061,\n",
       " 2292,\n",
       " 1005,\n",
       " 1055,\n",
       " 2156,\n",
       " 2054,\n",
       " 6433,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"This is a test-sentence, so let's see what happens\"\n",
    "#tokens = bert_tokenizer.tokenize(sent)\n",
    "#tokens = ['[CLS]'] + list(tokens) + ['[SEP]']\n",
    "#tokens = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "tokens = bert_tokenizer.encode(sent, max_length=30, add_special_tokens=True, pad_to_max_length=True)\n",
    "x = torch.tensor(tokens, requires_grad=False).long()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not bert_loaded:\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True,\n",
    "                                            output_attentions=True)\n",
    "    \n",
    "    bert_model.resize_token_embeddings(len(bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in = torch.stack([x, x], dim=0)\n",
    "x_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bert_model(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)\n",
    "#last hidden state\n",
    "outputs[0].shape #batchsize x seq_length x hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1].shape #pooled output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the documentation: \n",
    "\"This output is usually NOT a good summary of the semantic content of the input, \n",
    "you’re often better with averaging or pooling the sequence of hidden-states for the whole input sequence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[2]) #hidden_states at each output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[3]) #attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_embedded = word_embeddings(x)\n",
    "tokens_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden = outputs[0][0,:,:].squeeze()\n",
    "last_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(last_hidden, tokens_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden = last_hidden.view(1, last_hidden.shape[0], last_hidden.shape[1])\n",
    "last_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_size(l_in, pad, kernel, stride):\n",
    "    l_out = l_in + 2*pad - kernel\n",
    "    l_out /= stride\n",
    "    l_out += 1\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.sum(last_hidden, dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.mean(last_hidden, dim=1)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#text[0:10] = torch.zeros([10,10])\n",
    "keys = range(0,11)\n",
    "values = torch.zeros([len(keys), 10, 10])\n",
    "text = {**text, **dict(zip(keys, values))}\n",
    "text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = range(10,21)\n",
    "values = torch.zeros([len(keys), 10, 10])\n",
    "text = {**text, **dict(zip(keys, values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 30])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden.permute(0,2,1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 10])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool = torch.nn.AvgPool1d(2, stride=3)\n",
    "\n",
    "avg_pool(last_hidden.permute(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(tokens_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options for Encoding Sentences: \n",
    "1. Bert Embeddings (Raw): tokenise text and apply Bert Embeddings, no further processing [batch_size x seq_len x dim_e] => subsequent (sophisticated) Encoder should produce sentence representation [batch_size x dim_s]\n",
    "2. Last Hidden States: sequence encoded by Bert, powerful processing [batch_size x seq_len x dim_e] => subsequent (simple) Encoder produce sentence representation [batch_size x dim_s]\n",
    "3. Average over Last Hidden States: seq. encoded by Bert and average in the end to yield sentence representation [batch_size x dim_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A story children will love and learn from The King, the Mice and the Cheese by Nancy Gurney is an excellent children's book.  It is one that I well remember from my own childhood and purchased for my daughter who loves it.\\n\\nIt is about a king who has trouble with rude mice eating his cheese. He consults his wise men and they suggest cats to chase away the mice. The cats become a nuisance, so the wise men recommend the king bring in dogs to chase the cats away.  The cycle goes on until the mice are finally brought back to chase away the elephants, brought in to chase away the lions that'd chased away the dogs.\\n\\nThe story ends in compromise and friendship between the mice and the king.  The story also teaches cause and effect relationships.\\n\\nThe pictures that accompany the story are humorous and memorable.  I was thrilled to discover that it is back in print.  I *highly* recommend it for children ages 2 to 7.\""
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['reviewText'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 ms, sys: 0 ns, total: 15.4 ms\n",
      "Wall time: 18.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_elems=2\n",
    "encoded_in = [bert_tokenizer.encode(sent, max_length=30, add_special_tokens=True, pad_to_max_length=True) for sent in list(df['reviewText'])[:3]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = torch.tensor(encoded_in, requires_grad=False).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bert_model(x_in)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mt",
   "language": "python",
   "name": ".venv-mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
