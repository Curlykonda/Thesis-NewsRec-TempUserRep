Done copying.
Python 3.8.1
Python code starts now!
dataset : /scratch/Books_5.json.gz
pkl_path : /home/hbartsch/thesis-user-modelling/datasets/out-pickle
batch_size : 128
max_seq_length : 512
drop_org_reviews : 0
n_reviews : 4
Device: cuda:0
30522
Start reading: /scratch/Books_5.json.gz
0
1
2
3
Lines read: 3000001
Constructing DataFrame..
Cleaning DF..
Cleaning Text..
Encoding Text..
Traceback (most recent call last):
  File "prep_amazon_books.py", line 317, in <module>
    main(config)
  File "prep_amazon_books.py", line 296, in main
    user_dict, item_dict = preprocessDF_lisa(data_path, pkl_path, bert_tokenizer, bert_model,
  File "prep_amazon_books.py", line 236, in preprocessDF_lisa
    df, encoded_text = prep_text(df, bert_tokenizer, bert_model, batch_size, max_len=max_len, drop_org_reviews=drop_org_reviews, device=device)
  File "prep_amazon_books.py", line 133, in prep_text
    encoded_in = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text
  File "prep_amazon_books.py", line 133, in <listcomp>
    encoded_in = [tokenize_text_to_ids(text, bert_tokenizer, sent_tokenize, max_len) for text
  File "prep_amazon_books.py", line 71, in tokenize_text_to_ids
    sents = sent_tokenize(text)
  File "/home/hbartsch/.conda/envs/thesis-user-modelling/lib/python3.8/site-packages/nltk/tokenize/__init__.py", line 105, in sent_tokenize
    tokenizer = load('tokenizers/punkt/{0}.pickle'.format(language))
  File "/home/hbartsch/.conda/envs/thesis-user-modelling/lib/python3.8/site-packages/nltk/data.py", line 868, in load
    opened_resource = _open(resource_url)
  File "/home/hbartsch/.conda/envs/thesis-user-modelling/lib/python3.8/site-packages/nltk/data.py", line 993, in _open
    return find(path_, path + ['']).open()
  File "/home/hbartsch/.conda/envs/thesis-user-modelling/lib/python3.8/site-packages/nltk/data.py", line 701, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/PY3/english.pickle[0m

  Searched in:
    - '/home/hbartsch/nltk_data'
    - '/home/hbartsch/.conda/envs/thesis-user-modelling/nltk_data'
    - '/home/hbartsch/.conda/envs/thesis-user-modelling/share/nltk_data'
    - '/home/hbartsch/.conda/envs/thesis-user-modelling/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
    - ''
**********************************************************************

